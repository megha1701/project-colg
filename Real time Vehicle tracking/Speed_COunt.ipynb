{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mFailed to start the Kernel 'Python 3.10.9 64-bit'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. EPERM: operation not permitted, open 'C:\\PROGRA~1\\nodejs\\NODE_M~1\\npm\\bin\\kernel-v2-14144pDl09Tt6Hm5r.json'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# cap = cv2.VideoCapture('vehicle-counting.mp4')\n",
    "cap = cv2.VideoCapture('C:\\Users\\Lenovo\\Downloads\\project colg\\project colg\\WhatsApp Video 2023-04-17 at 11.10.50.mp4')\n",
    "# cap = cv2.VideoCapture('vehicle-counting.mp4')\n",
    "\n",
    "# initialize variables\n",
    "prev_frame = None\n",
    "prev_time = None\n",
    "min_width_rect = 10 # min width rectangle\n",
    "min_height_rect = 10 # min height rectangle\n",
    "count_line_position = 325\n",
    "# Initialize Subtractor\n",
    "algo = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "car_count = 0\n",
    "# Load car detection classifier\n",
    "car_classifier = cv2.CascadeClassifier('cars.xml')\n",
    "\n",
    "def center_handle(x, y, w, h):\n",
    "    x1 = int(w / 2)\n",
    "    y1 = int(h / 2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    "\n",
    "detect = []\n",
    "offset = 4# allowable offset\n",
    "counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame1 = cv2.resize(frame1, (640, 480))\n",
    "    frame1_copy = frame1.copy()\n",
    "\n",
    "    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey, (3, 3), 5)\n",
    "\n",
    "    # store the first frame and time\n",
    "    if prev_frame is None:\n",
    "        prev_frame = blur\n",
    "        prev_time = time.time()\n",
    "        continue\n",
    "\n",
    "    # calculate the absolute difference between the current frame and the previous frame\n",
    "    diff = cv2.absdiff(prev_frame, blur)\n",
    "    # applying on each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5, 5)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(dilatada, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw counting line\n",
    "    # cv2.line(frame1_copy, (25, count_line_position), (1208, count_line_position), (255, 127, 0), 3)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # validate size of detected object\n",
    "        validate_counter = (w >= min_width_rect) and (h >= min_height_rect)\n",
    "        if not validate_counter:\n",
    "            continue\n",
    "\n",
    "        # calculate the speed of the car\n",
    "        car_roi = grey[y-10:y+h+10, x-10:x+w+10]\n",
    "        car_rects = car_classifier.detectMultiScale(grey, 1.1, 3)\n",
    "\n",
    "        for (car_x, car_y, car_w, car_h) in car_rects:\n",
    "            if car_h > 20:\n",
    "                curr_time = time.time()\n",
    "                time_diff = curr_time - prev_time\n",
    "                speed = (car_w / time_diff) * 0.0268224  # conversion factor from pixels per second to miles per hour\n",
    "                prev_frame = blur\n",
    "                prev_time = curr_time\n",
    "\n",
    "            cv2.putText(frame1_copy, f\"Speed: {speed:.2f} mph\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # Draw rectangle around detected object\n",
    "            cv2.rectangle(frame1_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # check if the center of the bounding box crossed the counting line\n",
    "        center_y = int(y + h / 2)\n",
    "        if center_y >= count_line_position and center_y <= count_line_position + 5:\n",
    "            car_count += 1\n",
    "\n",
    "    # Display car count\n",
    "    cv2.putText(frame1_copy, f\"Car count: {car_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Traffic Analysis', frame1_copy)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "#Release the capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
