{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28045 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('Classification/train/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = training_set.class_indices\n",
    "\n",
    "inv_class_indices = {v: k for k, v in class_indices.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_class_indices = {0: 'Ambulance',\n",
    " 1: 'Barge',\n",
    " 2: 'Bicycle',\n",
    " 3: 'Boat',\n",
    " 4: 'Bus',\n",
    " 5: 'Car',\n",
    " 6: 'Cart',\n",
    " 7: 'Caterpillar',\n",
    " 8: 'Helicopter',\n",
    " 9: 'Limousine',\n",
    " 10: 'Motorcycle',\n",
    " 11: 'Segway',\n",
    " 12: 'Snowmobile',\n",
    " 13: 'Tank',\n",
    " 14: 'Taxi',\n",
    " 15: 'Truck',\n",
    " 16: 'Van'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 479ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 431ms/step\n",
      "1/1 [==============================] - 1s 573ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 459ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 489ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 1s 939ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 1s 931ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 1s 559ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 1s 593ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 0s 431ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 486ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 1s 615ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 508ms/step\n",
      "1/1 [==============================] - 0s 463ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 444ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 1s 528ms/step\n",
      "1/1 [==============================] - 0s 444ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import easyocr\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "detected_vehicles = {'numberplates': [], 'class_labels': [], 'speeds': [], 'counts': []}\n",
    "\n",
    "\n",
    "# Load pre-trained Haar Cascade classifier\n",
    "plate_cascade = cv2.CascadeClassifier('NUM_PLATE.xml')\n",
    "\n",
    "# cap = cv2.VideoCapture('vehicle-counting.mp4')\n",
    "cap = cv2.VideoCapture('WhatsApp Video 2023-05-02 at 01.42.18.mp4')\n",
    "# cap = cv2.VideoCapture('vehicle-counting.mp4')\n",
    "\n",
    "# initialize variables\n",
    "prev_frame = None\n",
    "prev_time = None\n",
    "min_width_rect = 10 # min width rectangle\n",
    "min_height_rect = 10 # min height rectangle\n",
    "count_line_position = 325\n",
    "# Initialize Subtractor\n",
    "# algo = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "car_count = 0\n",
    "# Load car detection classifier\n",
    "car_classifier = cv2.CascadeClassifier('cars.xml')\n",
    "\n",
    "def center_handle(x, y, w, h):\n",
    "    x1 = int(w / 2)\n",
    "    y1 = int(h / 2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    "# Initialize Subtractor\n",
    "algo = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "detect = []\n",
    "offset = 4# allowable offset\n",
    "counter = 0\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('vehicle_VGG19.h5')\n",
    "\n",
    "labels = ['Ambulance', 'Bus', 'Car', 'Limousine', 'Motorcycle', 'Tank', 'Taxi', 'Truck', 'Van']\n",
    "\n",
    "car_cascade = cv2.CascadeClassifier('cars.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    plate_text = 'Can\\'t read'\n",
    "    frame1 = cv2.resize(frame1, (640, 480))\n",
    "    frame1_copy = frame1.copy()\n",
    "    frame = frame1.copy()\n",
    "\n",
    "    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey, (3, 3), 5)\n",
    "    cars = car_cascade.detectMultiScale(grey, 1.1, 3)\n",
    "\n",
    "\n",
    "    for (x, y, w, h) in cars:\n",
    "        car_img = frame[y:y+h, x:x+w]\n",
    "        car_img = cv2.resize(car_img, (224, 224))\n",
    "        car_img = cv2.cvtColor(car_img, cv2.COLOR_BGR2RGB)\n",
    "        car_img = car_img / 255.0\n",
    "        car_img = np.expand_dims(car_img, axis=0)\n",
    "        \n",
    "        pred = model.predict(car_img)[0]\n",
    "        predicted_labels = inv_class_indices[np.argmax(pred)] \n",
    "        \n",
    "        \n",
    "        if predicted_labels in labels:\n",
    "            \n",
    "            cv2.rectangle(frame1_copy, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame1_copy, predicted_labels, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # store the first frame and time\n",
    "    if prev_frame is None:\n",
    "        prev_frame = blur\n",
    "        prev_time = time.time()\n",
    "        continue\n",
    "\n",
    "    # calculate the absolute difference between the current frame and the previous frame\n",
    "    diff = cv2.absdiff(prev_frame, blur)\n",
    "    # applying on each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5, 5)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(dilatada, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw counting line\n",
    "    # cv2.line(frame1_copy, (25, count_line_position), (1208, count_line_position), (255, 127, 0), 3)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # validate size of detected object\n",
    "        validate_counter = (w >= min_width_rect) and (h >= min_height_rect)\n",
    "        if not validate_counter:\n",
    "            continue\n",
    "\n",
    "        # calculate the speed of the car\n",
    "        car_roi = grey[y-10:y+h+10, x-10:x+w+10]\n",
    "        car_rects = car_classifier.detectMultiScale(grey, 1.1, 3)\n",
    "\n",
    "        for (car_x, car_y, car_w, car_h) in car_rects:\n",
    "            try:\n",
    "                plates = plate_cascade.detectMultiScale(grey, 1.3, 5)\n",
    "                # Loop through detected number plates\n",
    "                for (x, y, w, h) in plates:\n",
    "                    # Crop number plate from frame\n",
    "                    plate_img = grey[y:y + h, x:x + w]\n",
    "\n",
    "                    # Apply thresholding to enhance characters in number plate\n",
    "                    thresh = cv2.threshold(plate_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "                    #  read the number plate text\n",
    "                    plate_text = reader.readtext(thresh, paragraph=False)\n",
    "\n",
    "                    # Draw bounding box around number plate and display number plate text\n",
    "                    cv2.rectangle(frame1_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    try:\n",
    "\n",
    "                        cv2.putText(frame1_copy, str(plate_text[0][1]), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    except:\n",
    "                        cv2.putText(frame1_copy, \"Can't read\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            \n",
    "\n",
    "\n",
    "            except:\n",
    "                print(\"a\")\n",
    "\n",
    "            if car_h > 20:\n",
    "                curr_time = time.time()\n",
    "                time_diff = curr_time - prev_time\n",
    "                speed = (car_w / time_diff) * 0.0268224  # conversion factor from pixels per second to miles per hour\n",
    "                prev_frame = blur\n",
    "                prev_time = curr_time\n",
    "            if speed > 50 : \n",
    "                cv2.putText(frame1_copy, f\"Speed: {speed:.2f} mph - OVERSPEEDING\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            cv2.putText(frame1_copy, f\"Speed: {speed:.2f} mph\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # Draw rectangle around detected object\n",
    "            cv2.rectangle(frame1_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # check if the center of the bounding box crossed the counting line\n",
    "        center_y = int(y + h / 2)\n",
    "        if center_y >= count_line_position and center_y <= count_line_position + 5:\n",
    "            car_count += 1\n",
    "            try: \n",
    "                if predicted_labels and car_count and speed and str(plate_text[0][1]):\n",
    "                    detected_vehicles['numberplates'].append(str(plate_text[0][1]))\n",
    "                    detected_vehicles['class_labels'].append(predicted_labels)\n",
    "                    detected_vehicles['counts'].append(car_count)\n",
    "                    detected_vehicles['speeds'].append(speed)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Display car count\n",
    "    cv2.putText(frame1_copy, f\"Car count: {car_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Traffic Analysis', frame1_copy)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "#Release the capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "# create the PDF object\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "\n",
    "# set the font and font size\n",
    "pdf.set_font('Arial', 'B', 16)\n",
    "\n",
    "# create the table header\n",
    "pdf.cell(50, 10, 'Number Plate', border=1)\n",
    "pdf.cell(50, 10, 'Class Label', border=1)\n",
    "pdf.cell(30, 10, 'Speed', border=1)\n",
    "pdf.cell(30, 10, 'Count', border=1)\n",
    "pdf.ln()\n",
    "\n",
    "# loop through the detected_vehicles dictionary and add the data to the table\n",
    "for i in range(len(detected_vehicles['numberplates'])):\n",
    "    pdf.cell(50, 10, str(detected_vehicles['numberplates'][i]), border=1)\n",
    "    pdf.cell(30, 10, str(detected_vehicles['class_labels'][i]), border=1)\n",
    "    pdf.cell(30, 10, str(detected_vehicles['speeds'][i]), border=1)\n",
    "    pdf.cell(30, 10, str(detected_vehicles['counts'][i]), border=1)\n",
    "    pdf.ln()\n",
    "\n",
    "# save the PDF file\n",
    "pdf.output('detected_vehicles_report.pdf', 'F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
