{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20221220::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\project colg\\car speed and number of count.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m back_sub \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcreateBackgroundSubtractorMOG2()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Load YOLOv3\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m net \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mdnn\u001b[39m.\u001b[39;49mreadNet(\u001b[39m\"\u001b[39;49m\u001b[39myolov3.weights\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39myolov3.cfg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Load classes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m classes \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20221220::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load background subtractor\n",
    "back_sub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Load YOLOv3\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Load classes\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "# Define minimum confidence threshold\n",
    "conf_threshold = 0.5\n",
    "\n",
    "# Initialize variables\n",
    "count = 0\n",
    "car_positions = []\n",
    "\n",
    "while True:\n",
    "    # Read frames from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Stop the loop if end of video\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = back_sub.apply(frame)\n",
    "\n",
    "    # Apply morphological operations to reduce noise\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Pass frame through network\n",
    "    height, width, channels = frame.shape\n",
    "    scale = 0.00392\n",
    "    blob = cv2.dnn.blobFromImage(frame, scale, (416,416), (0,0,0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "\n",
    "    # Initialize lists for detected cars and their positions\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    car_boxes = []\n",
    "\n",
    "    # Loop through all detections and filter for cars\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter for cars\n",
    "            if classes[class_id] == \"car\" and confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Check if detection is inside foreground mask\n",
    "                if fg_mask[y:y+h,x:x+w].sum() > w * h * 0.4:\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    car_boxes.append([x, y, w, h])\n",
    "\n",
    "    # Apply non-max suppression to remove overlapping boxes\n",
    "    indices = cv2.dnn.NMSBoxes(car_boxes, confidences, conf_threshold, 0.4)\n",
    "\n",
    "    # Loop through filtered detections and count cars\n",
    "    for i in indices.flatten():\n",
    "        box = car_boxes[i]\n",
    "        x = box[0]\n",
    "        y = box[1]\n",
    "        w = box[2]\n",
    "        h = box[3]\n",
    "\n",
    "        matched = False\n",
    "        for car_position in car_positions:\n",
    "            if y > car_position[3] and y < car_position[3]+30:\n",
    "                car_position[3] = y\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            count += 1\n",
    "\n",
    "            car_positions.append([x, y, x+w, y+h])\n",
    "\n",
    "    # Display count on the video frame\n",
    "    cv2.putText(frame, 'Vehicle count: {}'.format(count), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Draw boxes around cars\n",
    "    for i in indices.flatten():\n",
    "        box = car_boxes[i]\n",
    "        x = box[0]\n",
    "        y = box[1]\n",
    "        w = box[2]\n",
    "        h = box[3]\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "     \n",
    "    cv2.imshow('video2', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20221220::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\project colg\\car speed and number of count.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load YOLOv3 network\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m net \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mdnn\u001b[39m.\u001b[39;49mreadNet(\u001b[39m\"\u001b[39;49m\u001b[39myolov3.weights\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39myolov3.cfg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Load names of all COCO objects\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project%20colg/car%20speed%20and%20number%20of%20count.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m classes \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20221220::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLOv3 network\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Load names of all COCO objects\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Get indices of vehicle class\n",
    "vehicle_class_ids = []\n",
    "for i, cls in enumerate(classes):\n",
    "    if cls in ['car', 'truck', 'bus', 'motorbike', 'bicycle']:\n",
    "        vehicle_class_ids.append(i)\n",
    "\n",
    "# Open video stream\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "while True:\n",
    "    # Read frame from video stream\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get frame dimensions\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Create blob from frame\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    # Set input to network\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Get output from network\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "    # Initialize lists for bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    # Loop over each output layer\n",
    "    for output in layerOutputs:\n",
    "        # Loop over each detection in output layer\n",
    "        for detection in output:\n",
    "            # Get class ID and confidence\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # Check if detection is a vehicle and has high enough confidence\n",
    "            if classID in vehicle_class_ids and confidence > 0.5:\n",
    "                # Increment vehicle count\n",
    "                num_vehicles += 1\n",
    "                cv2.putText(frame, str(num_vehicles), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,230), 2)\n",
    "    # Print number of vehicles\n",
    "    print(f\"Number of vehicles: {num_vehicles}\")\n",
    "    cv2.imshow('video2', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# Release video stream\n",
    "cap.release()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_14452\\3084053577.py:81: RuntimeWarning: divide by zero encountered in divide\n",
      "  speed = (w / time_diff) * 0.0268224  # conversion factor from pixels per second to miles per hour\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture('WhatsApp Video 2023-04-17 at 11.10.50.mp4')\n",
    "\n",
    "\n",
    "# initialize variables\n",
    "prev_frame = None\n",
    "prev_time = None\n",
    "\n",
    "\n",
    "\n",
    "min_width_rect = 25 # min width rectangle\n",
    "min_height_rect = 25 # min height rectangle\n",
    "\n",
    "count_line_position = 325\n",
    "# Initialize Subtractor\n",
    "algo = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "# Load car detection classifier\n",
    "car_classifier = cv2.CascadeClassifier('cars.xml')\n",
    "\n",
    "def center_handle(x, y, w, h):\n",
    "    x1 = int(w / 2)\n",
    "    y1 = int(h / 2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    "\n",
    "detect = []\n",
    "offset = 4# allowable offset\n",
    "counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    frame1 = cv2.resize(frame1, (540, 480))\n",
    "\n",
    "\n",
    "    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey, (3, 3), 5)\n",
    "\n",
    "    # store the first frame and time\n",
    "    if prev_frame is None:\n",
    "        prev_frame = blur\n",
    "        prev_time = time.time()\n",
    "        continue\n",
    "\n",
    "    # calculate the absolute difference between the current frame and the previous frame\n",
    "    diff = cv2.absdiff(prev_frame, blur)\n",
    "    # applying on each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5, 5)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    counterShape, h = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw counting line\n",
    "    cv2.line(frame1, (25, count_line_position), (1208, count_line_position), (255, 127, 0), 3)\n",
    "\n",
    "    for (i,c) in enumerate(counterShape):\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        # calculate the speed of the car\n",
    "        \n",
    "        validate_counter = (w >= min_width_rect) and (h >= min_height_rect)\n",
    "        if not validate_counter:\n",
    "            continue\n",
    "\n",
    "        # Detect cars using the classifier\n",
    "        car_rects = car_classifier.detectMultiScale(grey, 1.1, 3)\n",
    "\n",
    "        for (x, y, w, h) in car_rects:\n",
    "\n",
    "            if h > 30:\n",
    "                curr_time = time.time()\n",
    "                time_diff = curr_time - prev_time\n",
    "                speed = (w / time_diff) * 0.0268224  # conversion factor from pixels per second to miles per hour\n",
    "                prev_frame = blur\n",
    "                prev_time = curr_time\n",
    "\n",
    "\n",
    "            cv2.putText(frame1, f\"Speed: {speed:.2f} mph\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # Draw rectangle around detected object\n",
    "            cv2.rectangle(frame1, (x, y), (x + w, y + h), (9, 255, 8), 2)\n",
    "            center = center_handle(x, y, w, h)\n",
    "\n",
    "            detect.append(center)\n",
    "            cv2.circle(frame1, center, 4, (0, 8, 255), -1)\n",
    "\n",
    "            for (x, y) in detect:\n",
    "                # Check if the center of the detected object is within the counting area\n",
    "                if y > count_line_position  and y < (count_line_position + offset):\n",
    "                    counter += 1\n",
    "                    detect.remove((x, y))\n",
    "    \n",
    "    cv2.putText(frame1, \"VEHICLE COUNTER :\"+str (counter), (45,47),cv2.FONT_HERSHEY_SIMPLEX, 1, (8,0,255),2)\n",
    "\n",
    "    cv2.imshow('video2', frame1)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_14452\\1847956922.py:79: RuntimeWarning: divide by zero encountered in divide\n",
      "  speed = (car_w / time_diff) * 0.0268224  # conversion factor from pixels per second to miles per hour\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# cap = cv2.VideoCapture('vehicle-counting.mp4')\n",
    "cap = cv2.VideoCapture('D:\\project colg\\WhatsApp Video 2023-05-02 at 01.42.18.mp4')\n",
    "# cap = cv2.VideoCapture('vehicle-counting.mp4')\n",
    "\n",
    "# initialize variables\n",
    "prev_frame = None\n",
    "prev_time = None\n",
    "min_width_rect = 10 # min width rectangle\n",
    "min_height_rect = 10 # min height rectangle\n",
    "count_line_position = 325\n",
    "# Initialize Subtractor\n",
    "algo = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "car_count = 0\n",
    "# Load car detection classifier\n",
    "car_classifier = cv2.CascadeClassifier('cars.xml')\n",
    "\n",
    "def center_handle(x, y, w, h):\n",
    "    x1 = int(w / 2)\n",
    "    y1 = int(h / 2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    "\n",
    "detect = []\n",
    "offset = 4# allowable offset\n",
    "counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame1 = cv2.resize(frame1, (640, 480))\n",
    "    frame1_copy = frame1.copy()\n",
    "\n",
    "    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey, (3, 3), 5)\n",
    "\n",
    "    # store the first frame and time\n",
    "    if prev_frame is None:\n",
    "        prev_frame = blur\n",
    "        prev_time = time.time()\n",
    "        continue\n",
    "\n",
    "    # calculate the absolute difference between the current frame and the previous frame\n",
    "    diff = cv2.absdiff(prev_frame, blur)\n",
    "    # applying on each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5, 5)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(dilatada, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw counting line\n",
    "    # cv2.line(frame1_copy, (25, count_line_position), (1208, count_line_position), (255, 127, 0), 3)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # validate size of detected object\n",
    "        validate_counter = (w >= min_width_rect) and (h >= min_height_rect)\n",
    "        if not validate_counter:\n",
    "            continue\n",
    "\n",
    "        # calculate the speed of the car\n",
    "        car_roi = grey[y-10:y+h+10, x-10:x+w+10]\n",
    "        car_rects = car_classifier.detectMultiScale(grey, 1.1, 3)\n",
    "\n",
    "        for (car_x, car_y, car_w, car_h) in car_rects:\n",
    "            if car_h > 20:\n",
    "                curr_time = time.time()\n",
    "                time_diff = curr_time - prev_time\n",
    "                speed = (car_w / time_diff) * 0.0268224  # conversion factor from pixels per second to miles per hour\n",
    "                prev_frame = blur\n",
    "                prev_time = curr_time\n",
    "\n",
    "            cv2.putText(frame1_copy, f\"Speed: {speed:.2f} mph\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # Draw rectangle around detected object\n",
    "            cv2.rectangle(frame1_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # check if the center of the bounding box crossed the counting line\n",
    "        center_y = int(y + h / 2)\n",
    "        if center_y >= count_line_position and center_y <= count_line_position + 5:\n",
    "            car_count += 1\n",
    "\n",
    "    # Display car count\n",
    "    cv2.putText(frame1_copy, f\"Car count: {car_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Traffic Analysis', frame1_copy)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "#Release the capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('WhatsApp Video 2023-05-02 at 01.42.18.mp4')\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Set video frame size\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# Load pre-trained Haar Cascade classifier\n",
    "plate_cascade = cv2.CascadeClassifier('NUM_PLATE.xml')\n",
    "wanted = ['R-183-JF']\n",
    "\n",
    "while True:\n",
    "    # Read frame from video\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    frame1=frame\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect number plates using Haar Cascade classifier\n",
    "    plates = plate_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Loop through detected number plates\n",
    "    for (x, y, w, h) in plates:\n",
    "        # Crop number plate from frame\n",
    "        plate_img = gray[y:y + h, x:x + w]\n",
    "\n",
    "        # Apply thresholding to enhance characters in number plate\n",
    "        thresh = cv2.threshold(plate_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        #  read the number plate text\n",
    "        plate_text = reader.readtext(thresh, paragraph=False)\n",
    "\n",
    "        # Draw bounding box around number plate and display number plate text\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        try:\n",
    "\n",
    "            cv2.putText(frame, str(plate_text[0][1]), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "            if plate_text[0][1] in wanted:\n",
    "                cv2.putText(frame, \"SUSPICIOUS NUMBER PLATE DETECTED\", (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 4)\n",
    "            \n",
    "        except:\n",
    "            # cv2.putText(frame, \"Can't read\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            pass\n",
    "    # Display video frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
